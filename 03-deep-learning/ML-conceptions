1.1监督学习
典型任务：分类，提供标签；预测，提供特征和目标，即回归。回归和分类的方法可互用。

1.2无监督学习
聚类，训练数据未标记。数据可视化。降维，特征提取：将几个相关的特征合并为一个。异常检测（训练数据包含异常数据），新颖性检测（训练数据不包含“新”数据）。关联规则学习。

1.3半监督学习
部分已标记数据。照片托管服务（标记一次，检测所有）。可以先使用聚类进行分组，对分组标签，然后可以使用监督算法。

1.4自监督学习
完全未标记数据。随机屏蔽一部分，训练模型恢复。最后在标记数据上微调，即可学习映射（迁移学习）。训练期间使用“生成的标签”，侧重分类和回归。

1.5强化学习
智能体（学习系统），状态，动作，奖励，策略。机器人学习走路，deepming alphago打败柯洁。

1.6批量学习
离线学习：先训练，后使用。模型腐烂，数据漂移，需要更新数据并从头开始训练新版本。

1.7在线学习
增量学习：小批量数据。适合数据快速变化，计算资源有限，超大数据集。学习率：适应数据的速度。如果录入不良数据，系统性能会下降，需要异常检测算法。

1.8基于实例的学习
学习样例，使用相似性度量，泛化到新实例。

1.9基于模型的学习
典型的机器学习工作流程。为一组样例构建模型，使用该模型进行预测。

2.1性能指标：代价函数，衡量模型有多差；拟合函数（效用函数），衡量模型有多好。
训练模型：通过样例，找到使模型（类型和架构）最拟合数据的参数。

2.2数据不足
复杂问题，数据比算法更重要。2009 peter norvig [the unreasonable effectiveness of data]

2.3数据不具代表性
样本太小，采样偏差。采样方法缺陷：采样偏差。

2.4低质量数据
错误，异常值，噪声。丢弃，修复。

2.5无关特征
特征工程。特征选择，提取，创建新特征。

2.6过拟合数据
以偏概全。优化：选择参数较少的模型，收集更多数据，减少数据噪声。正则化：增加约束，使模型更简单。超参数：学习算法（而非模型）的参数，不受算法本身影响，训练前设置，训练中不变。

2.7欠拟合
模型太简单。优化：更多参数的模型，更好的特征，减少约束。

3.1[验证集，训练集]和测试集
3.2训练集，训练开发集（tran-dev），开发集，测试集
